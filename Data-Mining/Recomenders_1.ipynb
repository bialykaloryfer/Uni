{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "baab2c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>880</td>\n",
       "      <td>476</td>\n",
       "      <td>3</td>\n",
       "      <td>880175444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>879795543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "      <td>874795795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>882399156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "      <td>879959583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserID  MovieID  Rating  Timestamp\n",
       "0         196      242       3  881250949\n",
       "1         186      302       3  891717742\n",
       "2          22      377       1  878887116\n",
       "3         244       51       2  880606923\n",
       "4         166      346       1  886397596\n",
       "...       ...      ...     ...        ...\n",
       "99995     880      476       3  880175444\n",
       "99996     716      204       5  879795543\n",
       "99997     276     1090       1  874795795\n",
       "99998      13      225       2  882399156\n",
       "99999      12      203       3  879959583\n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD, SVDpp, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "column_names = ['UserID','MovieID', 'Rating','Timestamp']\n",
    "data = pd.read_csv('C:\\\\Users\\\\piotr\\\\Downloads\\\\ml-100k\\\\u.data', sep=\"\\t\", names=column_names)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca22cdaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  3.,  4., ..., nan, nan, nan],\n",
       "       [ 4., nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [ 5., nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan,  5., nan, ..., nan, nan, nan]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr_of_users = 943\n",
    "nr_of_movies = 1682\n",
    "\n",
    "matrix = np.full((nr_of_users, nr_of_movies), np.nan, dtype=float)\n",
    "def add_to_matrix(row):\n",
    "    matrix[row[\"UserID\"] - 1][row[\"MovieID\"] - 1] = row[\"Rating\"]\n",
    "\n",
    "data.apply(add_to_matrix, axis = 1)\n",
    "\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bea9876d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.        , 3.        , 4.        , ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       [4.        , 3.20766341, 3.03550597, ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       [3.88658948, 3.21110034, 3.04406695, ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       ...,\n",
       "       [5.        , 3.21247108, 3.03103246, ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       [3.88194469, 3.20956107, 3.03655095, ..., 2.        , 3.        ,\n",
       "        3.        ],\n",
       "       [5.        , 3.21313913, 3.03815886, ..., 2.        , 3.        ,\n",
       "        3.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def colaborative_filtering(matrix, limit_users = nr_of_users):\n",
    "  new_matrix = np.full((limit_users, nr_of_movies), np.nan, dtype=float)\n",
    "  def get_similarities_vec(v1, v2):\n",
    "    v_size = v1.shape[0]\n",
    "    mask = [not(np.isnan(v1[i])) and not(np.isnan(v2[i])) for i in range(v_size)]\n",
    "    v1_similarities = v1[mask]\n",
    "    v2_similarities = v2[mask]\n",
    "    return v1_similarities, v2_similarities\n",
    "\n",
    "  def cosine_sim(v1, v2):\n",
    "      dot_product = np.dot(v1, v2)\n",
    "      norm_product = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
    "      if norm_product == 0:\n",
    "          return 0.0\n",
    "      return dot_product / norm_product\n",
    "\n",
    "  ## return vector of cos similarities for all other users\n",
    "  def get_all_similarities(matrix, user1_nr):\n",
    "    cos_vector = np.zeros(nr_of_users)\n",
    "    def vectors_cos(user2_nr):\n",
    "      user1, user2 = matrix[user1_nr], matrix[user2_nr]\n",
    "      user1_sim, user2_sim = get_similarities_vec(user1, user2)\n",
    "      if user1_nr != user2_nr:\n",
    "        cos_vector[user2_nr] = cosine_sim(user1_sim, user2_sim)\n",
    "    for user_nr in range(matrix.shape[0]):\n",
    "      vectors_cos(user_nr)\n",
    "\n",
    "    return cos_vector\n",
    "\n",
    "  ## return vector of new ratings for given user\n",
    "  def new_ratings(predict_user_nr):\n",
    "      all_similarities = get_all_similarities(matrix, predict_user_nr)\n",
    "      new_ratings = np.zeros(nr_of_movies, dtype=float)\n",
    "      previous_ratings = matrix[predict_user_nr]\n",
    "      similarity_sum = np.zeros(nr_of_movies)\n",
    "\n",
    "      for user_nr in range(nr_of_users):\n",
    "          if user_nr == predict_user_nr:\n",
    "              continue\n",
    "\n",
    "          user_ratings = matrix[user_nr]\n",
    "          sim = all_similarities[user_nr]\n",
    "          mask = [bool(np.isnan(previous_ratings[i])) and not(np.isnan(user_ratings[i])) for i in range(nr_of_movies)]\n",
    "          new_ratings[mask] += user_ratings[mask] * sim\n",
    "          similarity_sum[mask] += sim\n",
    "\n",
    "      with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        predicted = np.true_divide(new_ratings, similarity_sum)\n",
    "        predicted[similarity_sum == 0] = np.nan\n",
    "\n",
    "      mask = [np.isnan(predicted[i]) for i in range(nr_of_movies)]\n",
    "      predicted[mask] = previous_ratings[mask]\n",
    "      return predicted\n",
    "\n",
    "  for user_nr in range(new_matrix.shape[0]):\n",
    "    new_matrix[user_nr] = new_ratings(user_nr)\n",
    "  return new_matrix\n",
    "\n",
    "new_ratings = colaborative_filtering(matrix, limit_users=25)\n",
    "new_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7ba4a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous val: [5. 1. 5. 5. 5. 3. 3. 3. 5. 1.]\n",
      "new ratings: [5. 1. 5. 5. 5. 3. 3. 3. 5. 1.]\n",
      "\n",
      "previous val: [ 4. nan nan nan nan nan nan nan nan nan]\n",
      "new ratings: [4.         2.43375069 4.11115734 4.44990081 3.73282881 3.82780177\n",
      " 3.69372438 3.21684492 4.49540061 2.24248622]\n",
      "\n",
      "previous val: [nan nan nan nan nan nan nan nan nan nan]\n",
      "new ratings: [3.49608059 2.4812708  4.08343002 4.43780051 3.65733559 3.8097227\n",
      " 3.69162611 3.22281981 4.31696279 2.24157826]\n",
      "\n",
      "previous val: [nan nan nan nan nan nan nan nan nan nan]\n",
      "new ratings: [3.50647861 2.47234156 4.24101216 4.45509687 3.74521707 3.83915767\n",
      " 3.69355639 3.22458816 4.50160864 2.24482926]\n",
      "\n",
      "previous val: [nan nan nan nan nan nan nan nan nan nan]\n",
      "new ratings: [3.4859839  2.43806161 4.10341191 4.45366968 3.74140184 3.84441659\n",
      " 3.69318365 3.22138553 4.5164253  2.24578914]\n",
      "\n",
      "previous val: [ 2. nan nan nan nan nan  2. nan nan nan]\n",
      "new ratings: [2.         2.44600892 4.10869523 4.44995129 3.72701458 3.83117506\n",
      " 2.         3.20721499 4.50044577 2.2345268 ]\n",
      "\n",
      "previous val: [nan nan nan nan nan nan nan  2. nan nan]\n",
      "new ratings: [3.48814555 2.44614975 4.11193783 4.44683604 3.74201471 3.82793997\n",
      " 3.6963683  2.         4.50225307 2.24008603]\n",
      "\n",
      "previous val: [nan nan nan nan nan nan nan nan nan nan]\n",
      "new ratings: [3.49969397 2.43721934 4.11257539 4.44655522 3.75010873 3.84658685\n",
      " 3.69319839 3.22327169 4.50492805 2.22581069]\n",
      "\n",
      "previous val: [nan nan nan nan nan nan nan nan nan nan]\n",
      "new ratings: [3.47998027 2.48784903 4.09805187 4.44027    3.75183719 3.80553271\n",
      " 3.69873437 3.20407643 4.50348539 2.25868272]\n",
      "\n",
      "previous val: [nan nan nan nan nan  4. nan nan nan nan]\n",
      "new ratings: [3.48833425 2.45001652 4.10793282 4.44873923 3.73508421 4.\n",
      " 3.69404079 3.21638924 4.50246412 2.24020386]\n",
      "\n",
      "previous val: [ 4. nan nan nan nan nan nan nan nan  2.]\n",
      "new ratings: [4.         2.44862616 4.10890869 4.45094591 3.72698577 3.83125777\n",
      " 3.69515792 3.21531725 4.50099848 2.        ]\n",
      "\n",
      "previous val: [nan nan nan nan nan nan nan nan nan nan]\n",
      "new ratings: [3.49783794 2.44688465 4.10713819 4.44643322 3.73564561 3.85063214\n",
      " 3.70719405 3.22296706 4.50646796 2.2408889 ]\n",
      "\n",
      "previous val: [ 5. nan nan nan nan  5.  3.  4. nan nan]\n",
      "new ratings: [5.         2.45157444 4.11233369 4.44626779 3.74158184 5.\n",
      " 3.         4.         4.50387908 2.24002039]\n",
      "\n",
      "previous val: [ 3. nan nan nan nan  5. nan nan nan nan]\n",
      "new ratings: [3.         2.43602701 4.11033921 4.44977131 3.7435641  5.\n",
      " 3.69319956 3.21443044 4.50591989 2.23945378]\n",
      "\n",
      "previous val: [ 4. nan nan nan nan nan nan  1. nan nan]\n",
      "new ratings: [4.         2.44703117 4.10165743 4.44497027 3.72821588 3.82971371\n",
      " 3.69735231 1.         4.49357825 2.2490565 ]\n",
      "\n",
      "previous val: [nan nan nan nan nan nan nan nan nan nan]\n",
      "new ratings: [3.48969208 2.45975643 4.10937536 4.44783018 3.74647165 3.82460466\n",
      " 3.6971714  3.21900822 4.50269465 2.24206094]\n",
      "\n",
      "previous val: [ 3. nan nan nan nan nan  3. nan nan nan]\n",
      "new ratings: [3.         2.45644268 4.12062587 4.45799568 3.74381957 3.82806962\n",
      " 3.         3.19572973 4.50431275 2.23024438]\n",
      "\n",
      "previous val: [ 3. nan  5. nan nan  5. nan nan nan nan]\n",
      "new ratings: [3.         2.45693304 5.         4.44939514 3.72875131 5.\n",
      " 3.69286087 3.2138098  4.50226134 2.2384981 ]\n",
      "\n",
      "previous val: [nan nan nan nan nan nan nan nan nan nan]\n",
      "new ratings: [3.48747227 2.44757212 4.10628701 4.45544607 3.74128402 3.83046097\n",
      " 3.68565739 3.21678503 4.4875126  2.2445815 ]\n",
      "\n",
      "previous val: [nan nan nan nan nan nan nan  4. nan nan]\n",
      "new ratings: [3.49810284 2.46596843 4.25004015 4.44156751 3.72369728 3.80234048\n",
      " 3.70172783 4.         4.49896404 2.25238082]\n",
      "\n",
      "previous val: [nan nan nan nan nan nan nan  1. nan nan]\n",
      "new ratings: [3.4946518  2.44768889 4.09236923 4.45596823 3.73732781 3.82732824\n",
      " 3.68701251 1.         4.5007616  2.23075335]\n",
      "\n",
      "previous val: [nan nan nan nan nan nan  4.  4. nan nan]\n",
      "new ratings: [3.48495227 2.44054134 4.10218395 4.44723847 3.75507045 3.82036244\n",
      " 4.         4.         4.50999336 2.23540184]\n",
      "\n",
      "previous val: [nan nan nan nan nan  5. nan nan nan nan]\n",
      "new ratings: [3.48652633 2.44378354 4.11768283 4.44946464 3.74920652 5.\n",
      " 3.69215723 3.22125586 4.50478292 2.24109967]\n",
      "\n",
      "previous val: [nan nan nan nan nan nan  4. nan nan nan]\n",
      "new ratings: [3.48795393 2.45620812 4.10693046 4.4481812  3.73234816 3.82752608\n",
      " 4.         3.21555904 4.50592489 2.2400539 ]\n",
      "\n",
      "previous val: [nan nan nan  5. nan  4. nan nan nan nan]\n",
      "new ratings: [3.49026747 2.44957942 4.10817141 5.         3.74449092 4.\n",
      " 3.69723747 3.22111748 4.50958337 2.24500174]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for nr, new_rating in enumerate(new_ratings):\n",
    "    print(f\"previous val: {matrix[nr][110:120]}\")\n",
    "    print(f\"new ratings: {new_rating[110:120]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "29b72799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_time(data, ratings_to_predict = None, user_test_size = None, experience_split = None):\n",
    "    pd_test = pd.DataFrame(columns=column_names)\n",
    "    pd_train = pd.DataFrame(columns=column_names)\n",
    "    user_to_experience = pd.DataFrame(columns=[\"UserID\", \"HistoryLen\"])\n",
    "    nr_of_users = 0\n",
    "    for user_nr, ratings in data.groupby(\"UserID\"):\n",
    "        ratings = ratings.sort_values(by='Timestamp', ascending=False)\n",
    "        limit = None\n",
    "\n",
    "        if ratings_to_predict:\n",
    "            limit = ratings_to_predict\n",
    "        if user_test_size:\n",
    "            nr_of_ratings = ratings.shape[0]\n",
    "            limit = round(user_test_size * nr_of_ratings + 0.5)\n",
    "\n",
    "        pd_test = pd.concat([pd_test,ratings[:limit]])\n",
    "        pd_train = pd.concat([pd_train,ratings[limit:]])\n",
    "        if experience_split:\n",
    "            new_row = pd.DataFrame([{'UserID': user_nr, 'HistoryLen': ratings.shape[0]}])\n",
    "            user_to_experience = pd.concat([user_to_experience, new_row])\n",
    "        nr_of_users += 1\n",
    "\n",
    "    return pd_train, pd_test, user_to_experience, nr_of_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ab0a08b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9889\n",
      "RMSE: 0.9612\n",
      "RMSE: 1.0609\n",
      "{'testset': 0.9888632638091445, 'low_experience': 1.060880797257871, 'top_experience': 0.961187420318332}\n",
      "RMSE: 0.9964\n",
      "RMSE: 0.9798\n",
      "RMSE: 1.0648\n",
      "{'testset': 0.9963754244337171, 'low_experience': 1.064843640066458, 'top_experience': 0.9798404804655072}\n",
      "RMSE: 1.0152\n",
      "RMSE: 1.0154\n",
      "RMSE: 1.0959\n",
      "{'testset': 1.0152070524046635, 'low_experience': 1.0958663530910715, 'top_experience': 1.015360016145473}\n",
      "RMSE: 1.0505\n",
      "RMSE: 1.0563\n",
      "RMSE: 1.0791\n",
      "{'testset': 1.050532920057816, 'low_experience': 1.0791023133081654, 'top_experience': 1.0562605096022974}\n",
      "RMSE: 1.1189\n",
      "RMSE: 1.1338\n",
      "RMSE: 1.1237\n",
      "{'testset': 1.1189199512748638, 'low_experience': 1.1237318841237183, 'top_experience': 1.13382029902064}\n"
     ]
    }
   ],
   "source": [
    "## acc rate using time-based split\n",
    "def get_acc(model, ratings_to_predict = None, user_test_size = None, experience_split = None):\n",
    "    pd_train, pd_test, user_to_experience, nr_of_users = split_by_time(data, ratings_to_predict, user_test_size, experience_split)\n",
    "    results = {x:None for x in [\"testset\", \"low_experience\", \"top_experience\"]}\n",
    "\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    trainset = Dataset.load_from_df(pd_train[['UserID', 'MovieID', 'Rating']], reader).build_full_trainset()\n",
    "    testset = list(zip(pd_test['UserID'], pd_test['MovieID'], pd_test['Rating']))\n",
    "\n",
    "    model.fit(trainset)\n",
    "    predictions = model.test(testset)\n",
    "    results[\"testset\"] = accuracy.rmse(predictions)\n",
    "    if experience_split:\n",
    "        user_to_experience = user_to_experience.sort_values(by=\"HistoryLen\", ascending=False)\n",
    "        top_experience_users = pd_test[pd_test[\"UserID\"].isin(user_to_experience[:round(nr_of_users*experience_split)][\"UserID\"])]\n",
    "        low_experience_users = pd_test[pd_test[\"UserID\"].isin(user_to_experience[round(nr_of_users * (1 - experience_split)):][\"UserID\"])]\n",
    "\n",
    "        top_experience_testset = list(zip(top_experience_users['UserID'], top_experience_users['MovieID'], top_experience_users['Rating']))\n",
    "        low_experience_testset = list(zip(low_experience_users['UserID'], low_experience_users['MovieID'], low_experience_users['Rating']))\n",
    "\n",
    "        top_experience_predictions = model.test(top_experience_testset)\n",
    "        low_experience_predictions = model.test(low_experience_testset)\n",
    "\n",
    "        results[\"top_experience\"] = accuracy.rmse(top_experience_predictions)\n",
    "        results[\"low_experience\"] = accuracy.rmse(low_experience_predictions)\n",
    "\n",
    "    return results\n",
    "\n",
    "model = SVD()\n",
    "print(get_acc(model, user_test_size = 0.1, experience_split=0.2))\n",
    "print(get_acc(model, user_test_size = 0.2, experience_split=0.2))\n",
    "print(get_acc(model, user_test_size = 0.5, experience_split=0.2))\n",
    "print(get_acc(model, user_test_size = 0.8, experience_split=0.2))\n",
    "print(get_acc(model, user_test_size = 0.99, experience_split=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "205d8bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item coverage: 16.83%\n",
      "Item diversity: 2.24%\n"
     ]
    }
   ],
   "source": [
    "def get_top_n(predictions, n):\n",
    "    user_pred = {}\n",
    "    top_n = {}\n",
    "    for uid, iid, _, est, _ in predictions:\n",
    "        if uid in user_pred:\n",
    "            user_pred[uid].append((iid, est))\n",
    "        else:\n",
    "            user_pred[uid] = [(iid, est)]\n",
    "\n",
    "    for uid, user_ratings in user_pred.items():\n",
    "        top_n[uid] = sorted(user_ratings, key=lambda x: x[1], reverse=True)[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "def get_coverage(predictions, n, nr_of_movies):\n",
    "    top_n = get_top_n(predictions, n)\n",
    "    recommended_items = set()\n",
    "    for user_ratings in top_n.values():\n",
    "        for iid, _ in user_ratings:\n",
    "            recommended_items.add(iid)\n",
    "    return len(recommended_items) / nr_of_movies\n",
    "\n",
    "## liczone z https://en.wikipedia.org/wiki/Diversity_index#Simpson_index\n",
    "def get_diversity(predictions, n, nr_of_movies):\n",
    "    top_n = get_top_n(predictions, n)\n",
    "    recommended_items = {}\n",
    "    nr_of_chosen_items = 0\n",
    "    for user_ratings in top_n.values():\n",
    "        for iid, _ in user_ratings:\n",
    "            if iid in recommended_items:\n",
    "                recommended_items[iid] += 1\n",
    "            else:\n",
    "                recommended_items[iid] = 1\n",
    "            nr_of_chosen_items += 1\n",
    "    simpson_index = 0\n",
    "    for val in recommended_items.values():\n",
    "        simpson_index += (val/nr_of_chosen_items)**2\n",
    "    return simpson_index\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "anti_testset = trainset.build_anti_testset()\n",
    "\n",
    "predictions = model.test(anti_testset)\n",
    "\n",
    "coverage = get_coverage(predictions, 10, nr_of_movies)\n",
    "print(f\"Item coverage: {coverage:.2%}\")\n",
    "\n",
    "diversity = get_diversity(predictions, 10, nr_of_movies)\n",
    "print(f\"Item diversity: {diversity:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9817be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
